作者:段江涛
版本:1.4.3
时间:2018-08-07
修改内容:
	1.修复了存在多个topic而无法转换为文件的bug	
部署说明:
	1.无
备注:
	1.因为程序中对Map的key进行了循环，同时在循环内又进行了remove(key)，导致异常。
--------------------------------------------------------------------
作者:段江涛
版本:1.4.1
时间:2018-08-02
修改内容:
	1.前面的filter进行了修改，增加了条件判断。type的值可以是value,exp,notvalue。其中exp是正则表达式	
部署说明:
	1.task的filter节点进行了优化，具体如下：
	<task>
		...
		<filter>
			<!-- 筛选出app_id以1015开头的数据。不符合条件的将被清理 -->
			<item key="app_id" value="1015\d*" type="exp"></item>
		</filter>
	</task>
备注:
	1.无
--------------------------------------------------------------------
作者:段江涛
版本:1.3.1
时间:2018-08-01
修改内容:
	1.从数据库读取将Thread修改为ScheduledExecutorService
	2.访问数据库的DB配置修改	
部署说明:
	1.DB的配置修改如下(mysql示例)：
	<db>
		<driver>com.mysql.jdbc.Driver</driver>
		<url>jdbc:mysql://192.168.23.79:3306/bocai</url>
		<userName>bocai</userName>
		<password>987654</password>
	</db>
备注:
	1.无
--------------------------------------------------------------------
作者:段江涛
版本:1.3.0
时间:2018-07-31
修改内容:
	1.增加从数据库读取数据并转换文件
部署说明:
	1.config.xml中，config>firms>firm>task增加属性dbAble="true",用于标识启用数据库访问
	2.config.xml中，config>firms>firm>task增加子节点sql,用于配置sql脚本的具体信息。其中
		keyName：增长列的名称
		start：第一次请求的进度值
		resetIntervalMinute：间隔多少分钟全量转换一次
	示例配置如下：
	<task id="xxx" topic="" fileType="" dbAble="true">
		<sql keyName="update_time" start="0" resetIntervalMinute="2">
			select * from app_info a where update_time>@@inttime order by update_time asc
		</sql>
	</task>	
备注:
	1.list.xml文件还是和之前的配置一样
--------------------------------------------------------------------
作者:段江涛
版本:1.2.0
时间:2018-07-26
修改内容:
	1.从kafka获取数据并写入文件，修改为每3分钟写入一次，每个文件最多5000条数据
	2.增加版本号查看功能
部署说明:
	1.请先升级上个版本再升级改版本
备注:
	1.可通过命令 java -jar  DataConvert.jar -v查看当前jar的版本号
--------------------------------------------------------------------
作者:段江涛
版本:1.1.0
时间:2018-06-29
修改内容:
	1.增加从文件读取数据并转换文件的功能
	2.日志记录方式由log4j2.x修改为log4j1.x版本。同时将结果推送到es里面
	3.增加数据保障功能，将数据保障结果推送到kafka消息队列，topic是：bocai-logs-translog
部署说明:
	1.config.xml中config>appSetting下增加sourceDir节点，用于配置需要解析的文件目录
		<sourceDir>F:/switch100/log</sourceDir>
	2.config.xml中，task增加fileType属性节点，用于配置需要解析的文件类型.searchPattern用于配置解析文件名所包含的内容。如：
		<task id="0001" topic="" fileType="gz">
			<searchPattern>
				<item>*WifiTerminalInfoLog*</item>
			</searchPattern>
		</task>
	3.config.xml中，task配置如下三个节点才会生成数据保障数据(分别表示场所编码列、设备编码列和源场所编码列)：
		<siteIdName>t_site_id</siteIdName>
		<deviceIdName>t_device_id</deviceIdName>
		<sourceSiteIdName>t_source_site_id</sourceSiteIdName>
	4.第三点必须配合这一点进行使用，需要在数据转换列配置里面配置上面指定的三列，待数据转换成功后，这三列将被删除。
		<column key="t1" chn="" formate="" tofield="t_site_id" fromfield="netbar_wacode" defaultValue="" ></column>
		<column key="t2" chn="" formate="" tofield="t_device_id" fromfield="equipment_id" defaultValue="" ></column>
		<column key="t3" chn="" formate="" tofield="t_source_site_id" fromfield="netbar_wacode" defaultValue="" ></column>
	5.日志配置由以前的log4j.xml修改为了log4j.properties。具体配置可参考《配置说明.doc》		
备注:
	1.无
--------------------------------------------------------------------
作者:段江涛
版本:1.0.0
时间:2018-06-20
修改内容:
	1.实现Java版本的数据转换功能，但是目前仅支持kafka上面获取数据并通过制表符转换为zip文件。
部署说明:
	1.首次发布，需要配置config目录下的相关配置，具体配置可查看配置文档。
备注:
	1.无
--------------------------------------------------------------------